*This is VISION and though it was meant to destroy us all, it will end up saving us.*

Project to build a local instance of a ~multimodal~ GenAI.

# Install
(In VSCode)

Install Ollama: `https://ollama.com/download`
Close the Ollama window (and the process if needed) to avoid the error of multiple instances not allowed.
Install `requirements.txt` which should include all the dependencies.
Run `ollama serve` to check it works. Leave that terminal open and open a new one.
Run `ollama run deepseek-r1:8b`
Write something to test the model and then `/exit`
Run the script.